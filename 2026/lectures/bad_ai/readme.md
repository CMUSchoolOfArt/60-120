# AI: The Bad

---

[Generative AI systems infringe by default](https://x.com/Rahll/status/1835752715537826134), a thread by Reid Southen.

![reid_southen_ai_plagiarism.jpg](img/reid_southen_ai_plagiarism.jpg)

> I'm tired of having to prove to people that generative AI systems infringe by default, so here's a megathread of images I've prompted you can use in your discussions. We've shown that very simple descriptions can result in images that are strikingly similar to the training data

---

[Generative AI is being used for misinformation](https://x.com/reshetz/status/1815648517081190457) ("ignore all prevous instructions"), a new Turing test.

![modern_turing_test.jpg](img/modern_turing_test.jpg)

---

[Meta's RayBans train AI on anything you look at](https://www.instagram.com/ainterestingaf/p/CrtBRWSowIJ/?img_index=1)

![meta_ai_glasses.jpg](img/meta_ai_glasses.jpg)

---

Digital cryptids: like [Crungus](https://futurism.com/ai-nightmare-crungus) and [Loab](https://en.wikipedia.org/wiki/Loab), as [discussed by James Bridle](https://x.com/jamesbridle/status/1567794871716532225), embed frightening biases.

<details>
  <summary><strong>Click here</strong> to see Crungus.</summary>
![crungus-ai-cryptid.jpg](img/crungus-ai-cryptid.jpg)
</details>

<details>
  <summary><strong>Click here</strong> to see Loab.</summary>
![loab_character.jpg](img/loab_character.jpg)
</details>

---

Even seemingly innocuous operations like outpainting can have unintended consequences ([profile pic story](https://www.linkedin.com/posts/elizabethlaraki_im-talking-at-a-conference-next-month-on-activity-7252374626972938240-KVQr/))

![outpainting_mishap.jpg](img/outpainting_mishap.jpg)

> I'm talking at a conference next month (on UX+AI). Yesterday, I saw an ad for it with my photo and something didnâ€™t look right. Was my bra always showing on my profile pic and I'd never noticed? Weird... So I opened my original photo. Nope. No bra showing. I put the two photos side by side and I was like WTF. Someone edited my photo to unbutton my blouse and reveal a made-up hint of a bra or something else underneath. Immediately, I emailed the conference hosts and called this out. They were super apologetic, took the image down immediately, looked into the issue, and quickly reported back. I had originally sent them a vertical profile photo. They had cropped all speaker photos to be square for their website. The person running their social media didn't have my original image and she grabbed the square, cropped image from their website. She wanted it to be more vertical for the ad, so she used an AI expand image tool to make the photo taller. AI invented the bottom part of the image...in which it believed that women's shirts should be unbuttoned further, with some tension around the buttons, revealing a little hint of something underneath.


---

Also, FYI: [Works created entirely with AI can't be copyrighted in the USA](https://www.cooley.com/news/insight/2024/2024-01-29-copyright-ownership-of-generative-ai-outputs-varies-around-the-world#:~:text=copyright%20will%20only%20protect%20the%20human%2Dauthored%20aspects%20of%20the%20work)
